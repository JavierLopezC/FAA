{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de la práctica 1 de **FAA**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Javier López Cano y Gonzalo Madrigal.** Grupo 1462."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# coding: utf-8\n",
    "from Datos import Datos\n",
    "import numpy as np\n",
    "from Clasificador import Clasificador, ClasificadorNaiveBayes\n",
    "from EstrategiaParticionado import ValidacionSimple, ValidacionCruzada\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En esta práctica hemos trabajado con el algoritmo de clasificación **Naive Bayes**. Hemos experimentado con los **modelos de partición** de los datos para la validación de resultados; hemos aplicado la corrección de Laplace al algoritmo para observar la mejora y finalmente hemos comparado los resultados obtenidos con los resultantes de ejecutar los métodos de la libreria **Scikit-Learn**. Por último, para un análisis más exhaustivo de los errores de clasificación hemos realizado una **matriz de confusión** y **la curva ROC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que compara una lista predicción y los datos reales correspondientes para calcular el error del **clasificador**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_sk(data, pred):\n",
    "    tot = 0\n",
    "    for i in range(0, len(pred)):\n",
    "        if pred[i] != data[i]:\n",
    "            tot += 1\n",
    "    tot /= len(pred)\n",
    "    #print(\"error de: \" + str(tot))\n",
    "    return tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba con dos ficheros.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar realizaremos pruebas con el fihero *Tic Tac Toe*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tic-tac-toe:\n",
      "\n",
      "nominalAtributos:\n",
      "[True, True, True, True, True, True, True, True, True, True]\n",
      "\n",
      "Diccionario:\n",
      "{'TLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'TMidSq': {'b': 0, 'o': 1, 'x': 2}, 'TRightSq': {'b': 0, 'o': 1, 'x': 2}, 'MLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'MMidSq': {'b': 0, 'o': 1, 'x': 2}, 'MRightSq': {'b': 0, 'o': 1, 'x': 2}, 'BLeftSq': {'b': 0, 'o': 1, 'x': 2}, 'BMidSq': {'b': 0, 'o': 1, 'x': 2}, 'BRightSq': {'b': 0, 'o': 1, 'x': 2}, 'Class': {'negative': 0, 'positive': 1}}\n",
      "\n",
      "Datos:\n",
      "[[2 2 2 ... 1 1 1]\n",
      " [2 2 2 ... 2 1 1]\n",
      " [2 2 2 ... 1 2 1]\n",
      " ...\n",
      " [1 2 1 ... 1 2 0]\n",
      " [1 2 1 ... 1 2 0]\n",
      " [1 1 2 ... 2 2 0]]\n"
     ]
    }
   ],
   "source": [
    "    tictac = Datos(\"tic-tac-toe.data\")\n",
    "    german = Datos(\"german.data\")\n",
    "    \n",
    "    print(\"Tic-tac-toe:\\n\")\n",
    "    print(\"nominalAtributos:\")\n",
    "    print(tictac.nominalAtributos)\n",
    "    print(\"\\nDiccionario:\")\n",
    "    print(tictac.diccionario)\n",
    "    print(\"\\nDatos:\")\n",
    "    print(tictac.datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestro clasificador **Naive-Bayes** con validación simple. Este tipo de particionado divide la lista en dos partes aleatorias de un tamaño determinado, una para entrenar y otra para probar las predicciones que hemos hecho. realizamos este proceso y las respectivas pruebas 100 veces y nos quedamos con los valores medios de error, ya que de hacerlo una única vez el resultado estaría demasiado sesgado por el resultado de la separación aleatoria. La principal ventaja respecto a la validación cruzada es que de esta forma la división de datos entrenamiento-prueba no depende del número de iteraciones. Por otro lado con este método hay algunas muestras que pueden quedar sin evaluar y otras que pueden ser evaluadas más de una vez.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos dos resultados: con y sin **corrección de Laplace**. La corrección de laplace nos evita caer en el error de hacerle \"creer\" a Naive-Bayes que porque no tengamos ningún ejemplo de pertenencia a una clase dados una serie de valores, no significa que la probabilidad sea automáticamente 0. **Suaviza el efecto de los ceros**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TicTacToe:\n",
      "\n",
      "Validación Simple\n",
      "\n",
      "Validando 100 veces con clasificador propio:\n",
      "Error medio sin laplace 0.3006315789473683\n",
      "Error medio con laplace 0.2478947368421054\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\n\\nTicTacToe:\")\n",
    "    print(\"\\nValidación Simple\")\n",
    "\n",
    "    print(\"\\nValidando 100 veces con clasificador propio:\")\n",
    "    error = 0\n",
    "    error_lap = 0\n",
    "    NB_laplace = 0.0\n",
    "    NB_noLap = 0.0\n",
    "    for _ in range(0, 100):\n",
    "        nb = ClasificadorNaiveBayes()\n",
    "        vs = ValidacionSimple()\n",
    "        ret = Clasificador.validacion(vs, tictac, nb)\n",
    "        error += ret[0]\n",
    "        error_lap += ret[1]\n",
    "    NB_laplace = error/100\n",
    "    NB_noLap = error_lap / 100\n",
    "    print(\"Error medio sin laplace \" + str(NB_laplace))\n",
    "    print(\"Error medio con laplace \" + str(NB_noLap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la misma prueba con MultinomialNV, método del paquete **scickit-learn** para comparar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando 100 veces con MultinomialNB:\n",
      "Error medio 0.26177083333333334\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando 100 veces con MultinomialNB:\")\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    tictac.datos = enc.fit_transform(tictac.datos)\n",
    "    atr = tictac.datos[:, :len(tictac.nominalAtributos) - 1]\n",
    "    clase = tictac.datos[:, len(tictac.nominalAtributos) - 1]\n",
    "    error = 0\n",
    "    Multi = 0.0\n",
    "    for _ in range(0, 100):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(atr, clase, test_size=0.1)\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(train_x, train_y)\n",
    "        res = nb.predict(test_x)\n",
    "        error += error_sk(test_y, res)\n",
    "    multi = error/100\n",
    "    print(\"Error medio \" + str(multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el valor medio obtenido es semejante al que nos salió de nuestra implementación con correción de **Laplace**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la misma prueba con GaussianNB, método del paquete **scickit-learn** para comparar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando 100 veces con GaussianNB:\n",
      "Error medio 0.2585416666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    print(\"\\nValidando 100 veces con GaussianNB:\")\n",
    "    enc.inverse_transform(tictac.datos)\n",
    "    atr = tictac.datos[:, :len(tictac.nominalAtributos) - 1]\n",
    "    clase = tictac.datos[:, len(tictac.nominalAtributos) - 1]\n",
    "    error = 0\n",
    "    gauss = 0.0\n",
    "    for _ in range(0, 100):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(atr, clase, test_size=0.1)\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(train_x, train_y)\n",
    "        res = nb.predict(test_x)\n",
    "        error += error_sk(test_y, res)\n",
    "    gauss = error / 100\n",
    "    print(\"Error medio \" + str(gauss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_laplace)\n",
    "salida += \"<td>-</td>\" \n",
    "salida += \"<td>-</td></tr>\" \n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_noLap)\n",
    "salida += \"<td>%f</td>\" % (multi)\n",
    "salida += \"<td>%f</td></tr></table>\" % (gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td><td>0.300632</td><td>-</td><td>-</td></tr><tr><td>NB con Laplace</td><td>0.247895</td><td>0.261771</td><td>0.258542</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a cambiar de estrategia de particionado: usaremos la validación cruzada. En este caso lo que hacemos es \"partir\" la lista de valores en k sublistas. Iteramos de tal forma que cada vez la sublista de test es una y las de train serán las demás.  Finalmente se hará la media entre los valores obtenidos en las pruebas para calcular el error promedio. La principal ventaja de este método es que el valor que con una única ejecución obtenemos valores fiables y resistentes a sesgos; además aseguramos que todos los datos habrán sido considerados tanto para entrenar como para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validacion Cruzada\n",
      "\n",
      "Validando con clasificador propio:\n",
      "Error en partición 0 sin Laplace: 0.3368421052631579\n",
      "Error en partición 0 con Laplace: 0.2631578947368421\n",
      "Error en partición 1 sin Laplace: 0.3157894736842105\n",
      "Error en partición 1 con Laplace: 0.3157894736842105\n",
      "Error en partición 2 sin Laplace: 0.23157894736842105\n",
      "Error en partición 2 con Laplace: 0.18947368421052632\n",
      "Error en partición 3 sin Laplace: 0.3157894736842105\n",
      "Error en partición 3 con Laplace: 0.25263157894736843\n",
      "Error en partición 4 sin Laplace: 0.3473684210526316\n",
      "Error en partición 4 con Laplace: 0.25263157894736843\n",
      "Error en partición 5 sin Laplace: 0.2631578947368421\n",
      "Error en partición 5 con Laplace: 0.25263157894736843\n",
      "Error en partición 6 sin Laplace: 0.23157894736842105\n",
      "Error en partición 6 con Laplace: 0.15789473684210525\n",
      "Error en partición 7 sin Laplace: 0.37894736842105264\n",
      "Error en partición 7 con Laplace: 0.3684210526315789\n",
      "Error en partición 8 sin Laplace: 0.2631578947368421\n",
      "Error en partición 8 con Laplace: 0.18947368421052632\n",
      "Error en partición 9 sin Laplace: 0.3368421052631579\n",
      "Error en partición 9 con Laplace: 0.30526315789473685\n",
      "Error medio sin laplace 0.30210526315789477\n",
      "Error medio con laplace 0.25473684210526315\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidacion Cruzada\")\n",
    "    print(\"\\nValidando con clasificador propio:\")\n",
    "    tictac = Datos(\"tic-tac-toe.data\")\n",
    "    nb = ClasificadorNaiveBayes()\n",
    "    vc = ValidacionCruzada()\n",
    "    error = Clasificador.validacion(vc, tictac, nb)\n",
    "    NB_laplace = error[1]\n",
    "    NB_noLap = error[0]\n",
    "    print(\"Error medio sin laplace \" + str(NB_noLap))\n",
    "    print(\"Error medio con laplace \" + str(NB_laplace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la misma prueba con MultinomialNB, método del paquete **scickit-learn** para comparar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando con MultinomialNB:\n",
      "Error por particiones: \n",
      "[0.26041666666666663, 0.26041666666666663, 0.26041666666666663, 0.26178010471204194, 0.26178010471204194]\n",
      "Error medio: 0.26096204188481675\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando con MultinomialNB:\")\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    tictac.datos = enc.fit_transform(tictac.datos)\n",
    "    atr = tictac.datos[:, :len(tictac.nominalAtributos) - 1]\n",
    "    clase = tictac.datos[:, len(tictac.nominalAtributos) - 1]\n",
    "    acierto = cross_val_score(MultinomialNB(), atr, clase)\n",
    "    error = []\n",
    "    for data in acierto:\n",
    "        error.append(1 - data)\n",
    "    print(\"Error por particiones: \")\n",
    "    print(error)\n",
    "    multi = sum(error) / len(error)\n",
    "    print(\"Error medio: \" + str(multi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la misma prueba con GaussianNB, método del paquete **scickit-learn** para comparar resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando con GaussianNB:\n",
      "Error por particiones: \n",
      "[0.26041666666666663, 0.26041666666666663, 0.49479166666666663, 0.40314136125654454, 0.26178010471204194]\n",
      "Error medio: 0.3361092931937173\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando con GaussianNB:\")\n",
    "    enc.inverse_transform(tictac.datos)\n",
    "    atr = tictac.datos[:, :len(tictac.nominalAtributos) - 1]\n",
    "    clase = tictac.datos[:, len(tictac.nominalAtributos) - 1]\n",
    "    acierto = cross_val_score(GaussianNB(), atr, clase)\n",
    "    error = []\n",
    "    for data in acierto:\n",
    "        error.append(1 - data)\n",
    "    print(\"Error por particiones: \")\n",
    "    print(error)\n",
    "    gauss = sum(error) / len(error)\n",
    "    print(\"Error medio: \" + str(gauss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_noLap)\n",
    "salida += \"<td>-</td>\" \n",
    "salida += \"<td>-</td></tr>\" \n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_laplace)\n",
    "salida += \"<td>%f</td>\" % (multi)\n",
    "salida += \"<td>%f</td></tr></table>\" % (gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td><td>0.302105</td><td>-</td><td>-</td></tr><tr><td>NB con Laplace</td><td>0.254737</td><td>0.260962</td><td>0.336109</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer las mismas pruebas con los datos del fichero *german*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "German:\n",
      "\n",
      "nominalAtributos:\n",
      "[True, False, True, True, False, True, True, False, True, True, False, True, False, True, True, False, True, False, True, True, True]\n",
      "\n",
      "Diccionario:\n",
      "{'A1': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}, 'A2': {}, 'A3': {'A30': 0, 'A31': 1, 'A32': 2, 'A33': 3, 'A34': 4}, 'A4': {'A40': 0, 'A41': 1, 'A410': 2, 'A42': 3, 'A43': 4, 'A44': 5, 'A45': 6, 'A46': 7, 'A48': 8, 'A49': 9}, 'A5': {}, 'A6': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}, 'A7': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}, 'A8': {}, 'A9': {'A91': 0, 'A92': 1, 'A93': 2, 'A94': 3}, 'A10': {'A101': 0, 'A102': 1, 'A103': 2}, 'A11': {}, 'A12': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3}, 'A13': {}, 'A14': {'A141': 0, 'A142': 1, 'A143': 2}, 'A15': {'A151': 0, 'A152': 1, 'A153': 2}, 'A16': {}, 'A17': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}, 'A18': {}, 'A19': {'A191': 0, 'A192': 1}, 'A20': {'A201': 0, 'A202': 1}, 'Class': {'1': 0, '2': 1}}\n",
      "\n",
      "Datos:\n",
      "[[ 0  6  4 ...  1  0  0]\n",
      " [ 1 48  2 ...  0  0  1]\n",
      " [ 3 12  4 ...  0  0  0]\n",
      " ...\n",
      " [ 3 12  2 ...  0  0  0]\n",
      " [ 0 45  2 ...  1  0  1]\n",
      " [ 1 45  4 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\n\\nGerman:\\n\")\n",
    "    print(\"nominalAtributos:\")\n",
    "    print(german.nominalAtributos)\n",
    "    print(\"\\nDiccionario:\")\n",
    "    print(german.diccionario)\n",
    "    print(\"\\nDatos:\")\n",
    "    print(german.datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestra implementación de **Naive-Bayes** con validación siple con los datos de German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "German:\n",
      "\n",
      "Validacion Simple\n",
      "\n",
      "Validando 100 veces con clasificador propio:\n",
      "Error medio sin laplace 0.28269999999999995\n",
      "Error medio con laplace 0.3020000000000001\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\n\\nGerman:\")\n",
    "    print(\"\\nValidacion Simple\")\n",
    "    print(\"\\nValidando 100 veces con clasificador propio:\")\n",
    "    error = 0\n",
    "    NB_laplace = 0.0\n",
    "    NB_noLap = 0.0\n",
    "    error_lap = 0\n",
    "    for _ in range(0, 100):\n",
    "        nb = ClasificadorNaiveBayes()\n",
    "        vs = ValidacionSimple()\n",
    "        ret = Clasificador.validacion(vs, german, nb)\n",
    "        error += ret[0]\n",
    "        error_lap += ret[1]\n",
    "    NB_noLap = error / 100\n",
    "    NB_laplace = error_lap / 100\n",
    "    print(\"Error medio sin laplace \" + str(NB_noLap))\n",
    "    print(\"Error medio con laplace \" + str(NB_laplace))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la prueba con el método *MultinomialNB* de sickit-learn, si bien en este caso no tiene much sentido porque trata todos los datos como nominales aún habiendo varios continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando 100 veces con MultinomialNB:\n",
      "Error medio 0.3628000000000002\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando 100 veces con MultinomialNB:\")\n",
    "    #En este caso no pretratamos los datos pues los transformaría todos en datos nominales y en este caso hay datos continuos\n",
    "    atr = german.datos[:, :len(german.nominalAtributos) - 1]\n",
    "    clase = german.datos[:, len(german.nominalAtributos) - 1]\n",
    "    error = 0\n",
    "    multi = 0.0\n",
    "    for _ in range(0, 100):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(atr, clase, test_size=0.1)\n",
    "        nb = MultinomialNB()\n",
    "        nb.fit(train_x, train_y)\n",
    "        res = nb.predict(test_x)\n",
    "        error += error_sk(test_y, res)\n",
    "    multi = error / 100\n",
    "    print(\"Error medio \" + str(multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la prueba con el método *GaussianNB* de sickit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando 100 veces con GaussianNB:\n",
      "Error medio 0.2700999999999999\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando 100 veces con GaussianNB:\")\n",
    "    atr = german.datos[:, :len(german.nominalAtributos) - 1]\n",
    "    clase = german.datos[:, len(german.nominalAtributos) - 1]\n",
    "    error = 0\n",
    "    gauss = 0.0\n",
    "    for _ in range(0, 100):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(atr, clase, test_size=0.1)\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(train_x, train_y)\n",
    "        res = nb.predict(test_x)\n",
    "        error += error_sk(test_y, res)\n",
    "    gauss = error/100\n",
    "    print(\"Error medio \" + str(gauss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_noLap)\n",
    "salida += \"<td>-</td>\" \n",
    "salida += \"<td>-</td></tr>\" \n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_laplace)\n",
    "salida += \"<td>%f</td>\" % (multi)\n",
    "salida += \"<td>%f</td></tr></table>\" % (gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td><td>0.282700</td><td>-</td><td>-</td></tr><tr><td>NB con Laplace</td><td>0.302000</td><td>0.362800</td><td>0.270100</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a hacer las pruebas con validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validacion Cruzada\n",
      "\n",
      "Validando con clasificador propio:\n",
      "Error en partición 0 sin Laplace: 0.41\n",
      "Error en partición 0 con Laplace: 0.39\n",
      "Error en partición 1 sin Laplace: 0.26\n",
      "Error en partición 1 con Laplace: 0.3\n",
      "Error en partición 2 sin Laplace: 0.29\n",
      "Error en partición 2 con Laplace: 0.28\n",
      "Error en partición 3 sin Laplace: 0.23\n",
      "Error en partición 3 con Laplace: 0.3\n",
      "Error en partición 4 sin Laplace: 0.3\n",
      "Error en partición 4 con Laplace: 0.33\n",
      "Error en partición 5 sin Laplace: 0.24\n",
      "Error en partición 5 con Laplace: 0.27\n",
      "Error en partición 6 sin Laplace: 0.31\n",
      "Error en partición 6 con Laplace: 0.3\n",
      "Error en partición 7 sin Laplace: 0.3\n",
      "Error en partición 7 con Laplace: 0.28\n",
      "Error en partición 8 sin Laplace: 0.25\n",
      "Error en partición 8 con Laplace: 0.3\n",
      "Error en partición 9 sin Laplace: 0.31\n",
      "Error en partición 9 con Laplace: 0.29\n",
      "Error medio sin laplace 0.29\n",
      "Error medio con laplace 0.304\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidacion Cruzada\")\n",
    "    print(\"\\nValidando con clasificador propio:\")\n",
    "    german = Datos(\"german.data\")\n",
    "    nb = ClasificadorNaiveBayes()\n",
    "    vc = ValidacionCruzada()\n",
    "    error = Clasificador.validacion(vc, german, nb)\n",
    "\n",
    "    NB_noLap = error[0]\n",
    "    NB_laplace = error[1]\n",
    "    print(\"Error medio sin laplace \" + str(error[0]))\n",
    "    print(\"Error medio con laplace \" + str(error[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la prueba con el método *MultinomialNB* de sickit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando con MultinomialNB:\n",
      "Error por particiones: \n",
      "[0.31499999999999995, 0.37, 0.32999999999999996, 0.41000000000000003, 0.375]\n",
      "Error medio: 0.36\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando con MultinomialNB:\")\n",
    "    #En este caso no pretratamos los datos pues los transformaría todos en datos nominales y en este caso hay datos continuos\n",
    "    atr = german.datos[:, :len(german.nominalAtributos) - 1]\n",
    "    clase = german.datos[:, len(german.nominalAtributos) - 1]\n",
    "    acierto = cross_val_score(MultinomialNB(), atr, clase)\n",
    "    error = []\n",
    "    for data in acierto:\n",
    "        error.append(1 - data)\n",
    "    print(\"Error por particiones: \")\n",
    "    print(error)\n",
    "    multi = sum(error) / len(error)\n",
    "    print(\"Error medio: \" + str(multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos la prueba con el método *GaussianNB* de sickit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validando con GaussianNB:\n",
      "Error por particiones: \n",
      "[0.29500000000000004, 0.28, 0.24, 0.30500000000000005, 0.21999999999999997]\n",
      "Error medio: 0.268\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nValidando con GaussianNB:\")\n",
    "    atr = german.datos[:, :len(german.nominalAtributos) - 1]\n",
    "    clase = german.datos[:, len(german.nominalAtributos) - 1]\n",
    "    acierto = cross_val_score(GaussianNB(), atr, clase)\n",
    "    error = []\n",
    "    for data in acierto:\n",
    "        error.append(1 - data)\n",
    "    print(\"Error por particiones: \")\n",
    "    print(error)\n",
    "    gauss = sum(error) / len(error)\n",
    "    print(\"Error medio: \" + str(gauss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_noLap)\n",
    "salida += \"<td>-</td>\" \n",
    "salida += \"<td>-</td></tr>\" \n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (NB_laplace)\n",
    "salida += \"<td>%f</td>\" % (multi)\n",
    "salida += \"<td>%f</td></tr></table>\" % (gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>MultinomialNB</th><th>Gausssian</th></tr><tr><td>NB sin Laplace</td><td>0.290000</td><td>-</td><td>-</td></tr><tr><td>NB con Laplace</td><td>0.304000</td><td>0.360000</td><td>0.268000</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
